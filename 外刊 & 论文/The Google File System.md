---
source: https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf
---
## Abstract

We have designed and implemented the Google File System, a [[scalable]] [[distributed]] file system for large [[distributed]] data-intensive applications. It provides fault tolerance while running on inexpensive [[commodity]] hardware, and it delivers high [[aggregate]] performance to a large number of clients. 

While sharing many of the same goals as previous [[distributed]] file systems, our design has been driven by [[observations]] of our application [[workload|workloads]] and technological environment, both current and [[anticipated]], that reflect a marked [[departure]] from some earlier file system [[assumptions]]. This has led us to reexamine traditional choices and explore [[radically]] different design points. 

The file system has successfully met our storage needs. It is widely deployed [[within]] Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. 

In this paper, we present file system interface extensions designed to support [[distributed]] applications, discuss many aspects of our design, and report measurements from both micro-[[benchmark|benchmarks]] and real world use.

## General Terms

Design, reliability, performance, measurement

## Keywords 

Fault tolerance, [[scalable|scalability]], data storage, clustered storage

## 1    Introduction

We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs. GFS shares many of the same goals as previous [[distributed]] file systems such as performance, [[scalable|scalability]], reliability, and availability. However, its design has been driven by key [[observations]] of our application [[workload|workloads]] and technological environment, both current and [[anticipated]], that reflect a marked [[departure]] from some earlier file system design [[assumptions]]. We have reexamined traditional choices and explored [[radically]] different points in the design space.

**First, component failures are the [[norm]] rather than the exception.** The file system consists of hundreds or even thousands of storage machines built from inexpensive [[commodity]] parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually [[guarantee]] that some are not functional at any given time and some will not recover from their current failures. We have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. Therefore, **constant monitoring**, **error detection**, **fault tolerance**, and **automatic recovery** must be integral to the system.

**Second, files are huge by traditional standards.** Multi-GB files are common. Each file typically contains many application objects such as web documents. When we are regularly working with fast growing data sets of many TBs [[comprise|comprising]] billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it. As a result, design [[assumptions]] and parameters such as I/O operation and blocksizes have to be revisited.

**Third, most files are [[mutate|mutated]] by appending new data rather than overwriting existing data.** Random writes [[within]] a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these [[characteristics]]. Some may [[constitute]] large repositories that data analysis programs scan through. Some may be data streams continuously generated by running applications. Some may be [[archival]] data. Some may be [[intermediate]] results produced on one machine and processed on another, whether [[simultaneously]] or later in time. Given this access pattern on huge files, appending becomes the focus of performance optimization and atomicity [[guarantee|guarantees]], while caching data blocks in the client loses its [[appeal]].

**Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.** For example, we have relaxed GFS’s [[consistency]] model to [[vastly]] simplify the file system without [[impose|imposing]] an [[onerous]] burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. These will be discussed in more details later in the paper.

Multiple GFS clusters are currently deployed for different purposes. The largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on [[distinct]] machines on a continuous basis.

## 2    Design Overview

### 2.1    [[Assumptions]]

In designing a file system for our needs, we have been guided by [[assumptions]] that offer both challenges and opportunities. We [[allude|alluded]] to some key [[observations]] earlier and now lay out our [[assumptions]] in more details.

- The system is built from many inexpensive [[commodity]] components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis. 
	
- The system stores a [[modest]] number of **large files**. We expect a few million files, each typically 100 MB or larger in size. Multi-GB files are the common case and should be managed efficiently. Small files must be supported, but we need not optimize for them. 
	
- The [[workload|workloads]] primarily consist of two kinds of reads: **large streaming reads** and **small random reads**. In large streaming reads, individual operations typically read hundreds of KBs, more commonly 1 MB or more. Successive operations from the same client often read through a contiguous region of a file. A small random read typically reads a few KBs at some [[arbitrary]] offset. Performance-conscious applications often batch and sort their small reads to advance [[steadily]] through the file rather than go backand forth.
	
- The [[workload|workloads]] also have many large, sequential writes that append data to files. Typical operation sizes are similar to those for reads. Once written, files are [[seldom]] modified again. Small writes at [[arbitrary]] positions in a file are supported but do not have to be efficient.
	
- The system must efficiently implement well-defined [[semantics]] for multiple clients that concurrently append to the same file. Our files are often used as producer-consumer queues or for many-way merging. Hundreds of producers, running one per machine, will concurrently append to a file. Atomicity with minimal synchronization overhead is essential. The file may be read later, or a consumer may be reading through the file [[simultaneously]]. 
	
- High [[sustained]] [[bandwidth]] is more important than low latency. Most of our target applications place a [[premium]] on processing data in [[bulk]] at a high rate, while few have [[stringent]] response time requirements for an individual read or write.

### 2.2 Interface

GFS provides a familiar file system interface, though it does not implement a standard API such as POSIX. Files are organized [[hierarchically]] in directories and [[identify|identified]] by pathnames. We support the usual operations to create, delete, open, close, read, and write files. 

Moreover, GFS has **snapshot** and **record append operations**. Snapshot creates a copy of a file or a directory tree at low cost. Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual client’s append. It is useful for implementing **multi-way merge results** and **producer-consumer queues** that many clients can [[simultaneously]] append to without additional locking. We have found these types of files to be invaluable in building large [[distributed]] applications. Snapshot and record append are discussed further in Sections 3.4 and 3.3 [[respectively]].

### 2.3 [[Architecture]] 

A GFS cluster consists of **a single master** and **multiple chunkservers** and is accessed by **multiple clients**, as shown in [[Figure]] 1. Each of these is typically a [[commodity]] Linux machine running a user-level server process. It is easy to run both a chunkserver and a client on the same machine, as long as machine resources permit and the lower reliability caused by running possibly [[flaky]] application code is acceptable. 

![[GFS Architecture.png|700]]

Files are divided into **fixed-size chunks**. Each chunk is [[identify|identified]] by an immutable and globally unique 64 bit, **chunk [[handle]]** assigned by the master at the time of chunk creation. **Chunkservers** store chunks on **local disks** as Linux files and read or write chunk data specified by a chunkhandle and byte range. For reliability, each chunkis [[replicated]] on multiple chunkservers. By default, we store **three** [[replicas]], though users can [[designate]] different replication levels for different regions of the file namespace. 

The master maintains **all file system metadata**. This includes the **namespace**, **access control information**, **the mapping from files to chunks**, **and the current locations of chunks**. It also controls **system-wide activities** such as **chunk [[lease]] management**, **garbage collection** of [[orphaned]] chunks, and chunk [[migration]] between chunkservers. The master **periodically communicates** with each chunkserver in **HeartBeat** messages to **give it instructions** and **collect its state**. 

**GFS client code** linked into each application implements the file system API and communicates with the master and chunkservers to read or write data on behalf of the application. Clients [[interact]] with the master for metadata operations, but **all data-[[bear|bearing]] communication goes directly to the chunkservers**. We do not provide the POSIX API and therefore need not hookinto the Linux vnode layer. 

Neither the client nor the chunk server caches file data. Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached. Not having them simplifies the client and the overall system by [[eliminate|eliminating]] cache [[coherence]] issues. (Clients do cache metadata, however.) Chunkservers need not cache file data because chunks are stored as local files and so Linux’s buffer cache already keeps frequently accessed data in memory.

### 2.4 Single Master

Having a single master [[vastly]] **simplifies our design** and enables the master to make [[sophisticated]] chunk placement and replication decisions using global knowledge. However, we must minimize its [[involvement]] in reads and writes so that it does not become a bottleneck. **Clients never read and write file data through the master**. Instead, a client asks the master which chunkservers it should contact. It caches this information for a limited time and interacts with the chunkservers directly for many subsequent operations. 

Let us explain the interactions for a simple read with reference to [[Figure]] 1. First, **using the fixed chunk size**, **the client** translates the **file name** and **byte offset** specified by the application into a chunkindex [[within]] the file. Then, it sends the master a request containing the file name and chunk index. The master replies with the [[corresponding]] chunk [[handle]] and locations of the [[replicas]]. 

The client caches this information using the **file name** and **chunk index** as the key. The client then sends a request to one of the [[replicas]], most likely the closest one. The request specifies the chunk [[handle]] and a byte range [[within]] that chunk. Further reads of the same chunk require no more client-master interaction until the cached information expires or the file is [[reopened]]. In fact, the client typically asks for multiple chunks in the same request and the master can also include the information for chunks immediately following those requested. This extra information [[sidesteps]] several future client-master interactions at practically no extra cost.

### 2.5 Chunk Size

Chunk size is one of the key design parameters. We have chosen **64 MB**, which is much larger than typical file system blocksizes. Each chunk [[replicas|replica]] is stored as a plain Linux file on a chunk server and is extended only as needed. Lazy space allocation avoids wasting space due to internal [[fragmentation]], perhaps the greatest objection against such a large chunk size.

A large chunksize offers several important advantages. First, it reduces clients’ need to [[interact]] with the master because reads and writes on the same chunkrequire only one initial request to the master for chunklocation information. The reduction is especially significant for our [[workload|workloads]] because applications mostly read and write large files sequentially. Even for small random reads, the client can comfortably cache all the chunklocation information for a multi-TB working set. Second, since on a large chunk, a client is more likely to perform many operations on a given chunk, it can reduce network overhead by keeping a persistent TCP connection to the chunkserver over an extended period of time. Third, it reduces the size of the metadata stored on the master. This allows us to keep the metadata in memory, which in turn brings other advantages that we will discuss in Section 2.6.1.

On the other hand, a large chunksize, even with lazy space allocation, has its disadvantages. A small file consists of a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file. In practice, hot spots have not been a major issue because our applications mostly read large multi-chunkfiles sequentially.

However, hot spots did develop when GFS was first used by a batch-queue system: an executable was written to GFS as a single-chunkfile and then started on hundreds of machines at the same time. The few chunkservers storing this executable were overloaded by hundreds of simultaneous requests. We fixed this problem by storing such executables with a higher replication factor and by making the batchqueue system stagger application start timesjj. A potential long-term solution is to allow clients to read data from other clients in such situations.